{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f0f4fe",
   "metadata": {},
   "source": [
    "# GRU\n",
    "\n",
    "* GRU is an advancement of the standard RNN.\n",
    "* GRUs are very similar to LSTM.\n",
    "<p align=\"left\">\n",
    "    <br><br>\n",
    "    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<em>GRU</em> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<em>LSTM</em>\n",
    "    <img src=\"https://d2l.ai/_images/gru-3.svg\" height=\"520\" width=\"440\" align=\"left\">\n",
    "    <img src = \"https://d2l.ai/_images/lstm-3.svg\" height=\"520\" width=\"440\">\n",
    "    </p><br><br>\n",
    "* Just like LSTM, GRU uses gates to control the flow of information.\n",
    "    - **Reset gate** is used to decide how much past information to forget or to remember.\n",
    "    - **Update gate** is used to capture long-term dependencies in sequence.\n",
    "    - **Hidden state** - Finally, we compute the hidden state using candidate hidden state and update gate\n",
    "* GRU are simpler then LSTM due to which they are faster to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d317c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf026763",
   "metadata": {},
   "source": [
    "## Step by Step GRU \n",
    "- <font size=3>Step 1: Reset Gate And Update Gate<br></font>\n",
    "    \\begin{split}\\begin{aligned}\n",
    "    \\mathbf{R}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xr} + \\mathbf{H}_{t-1} \\mathbf{W}_{hr} + \\mathbf{b}_r)\\\\\n",
    "    \\mathbf{Z}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xz} + \\mathbf{H}_{t-1} \\mathbf{W}_{hz} + \\mathbf{b}_z)\n",
    "    \\end{aligned}\\end{split}<br>\n",
    "    <img src = \"https://d2l.ai/_images/gru-1.svg\" height=\"620\" width=\"380\">\n",
    "<br><br>\n",
    "\n",
    "- <font size=3>Step 2: Candidate Hidden state<br></font>\n",
    "    \\begin{split}\\begin{aligned}\n",
    "    \\tilde{\\mathbf{H}}_t = \\tanh(\\mathbf{X}_t \\mathbf{W}_{xh} + \\left(\\mathbf{R}_t \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{hh} + \\mathbf{b}_h)\n",
    "    \\end{aligned}\\end{split}<br>\n",
    "    <img src = \"https://d2l.ai/_images/gru-2.svg\" height=\"720\" width=\"480\"><br>\n",
    "<br><br>\n",
    "\n",
    "- <font size=3>Step 3: Hidden state<br></font>\n",
    "    \\begin{split}\\begin{aligned}\n",
    "    \\mathbf{H}_t = \\mathbf{Z}_t \\odot \\mathbf{H}_{t-1}  + (1 - \\mathbf{Z}_t) \\odot \\tilde{\\mathbf{H}}_t.\n",
    "    \\end{aligned}\\end{split}<br>\n",
    "    <img src = \"https://d2l.ai/_images/gru-3.svg\" height=\"720\" width=\"480\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba693d",
   "metadata": {},
   "source": [
    "## GRU Equations:\n",
    "Input vector:&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\large {X_t} $\n",
    "<br><br>\n",
    "Reset Gate: &ensp;&nbsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\large R_t = \\sigma(W_{xr} X_t + W_{hr} H_{t-1}) $\n",
    "<br><br>\n",
    "Update Gate:&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $ \\large Z_t = \\sigma(W_{xz} X_t + W_{hz} H_{t-1})$\n",
    "<br><br>\n",
    "Candidate hidden state: &emsp; $ \\large \\tilde H_t = tanh(W_{xh} X_t + R_t * (W_{hh} H_{t-1}) )$\n",
    "<br><br>\n",
    "Hidden state: &emsp;&emsp;&emsp;&emsp;&emsp; $ \\large H_t = Z_t*H_{t-1} + (1-Z_t)*\\tilde H_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c993f4f",
   "metadata": {},
   "source": [
    "Reference: [Dive into Deep Learning](https://d2l.ai/chapter_recurrent-modern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8fecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.w_xr = nn.Linear(input_size, hidden_size)\n",
    "        self.w_hr = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.w_xz = nn.Linear(input_size, hidden_size)\n",
    "        self.w_hz = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.w_xh = nn.Linear(input_size, hidden_size)\n",
    "        self.w_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        #initializing hidden state as a tensor of zeros\n",
    "        # shape -> num_layers, batch_size, hidden_size\n",
    "        hidden = torch.zeros((1,1,hidden_size), dtype=torch.float32)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, x, hidden):   \n",
    "        reset_gate = torch.sigmoid(self.w_xr(x) + self.w_hr(hidden))\n",
    "        \n",
    "        update_gate = torch.sigmoid(self.w_xz(x) + self.w_hz(hidden))\n",
    "        \n",
    "        candidate = torch.tanh(self.w_xh(x) + torch.mul(reset_gate, self.w_hh(hidden)) )\n",
    "        \n",
    "        hidden_state = torch.mul(update_gate, hidden) + torch.mul((1-update_gate), candidate)\n",
    "        \n",
    "        return hidden_state, hidden_state[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
