{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678cca3c",
   "metadata": {},
   "source": [
    "# RNN\n",
    "- <font size=3> Handle variable - length sequences</font>\n",
    "- <font size=3> Track long-term dependencies</font>\n",
    "- <font size=3> Maintain information about order</font>\n",
    "- <font size=3> Share parameters across the sequence.</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c99d3530",
   "metadata": {},
   "source": [
    "<p align=left> \n",
    "<img src = \"https://cs231n.github.io/assets/rnn/rnn_blackbox.png\" height=\"720\" width=\"120\" align=\"left\">\n",
    "    <img src = \"https://cs231n.github.io/assets/rnn/unrolledRNN.png\" height=\"720\" width=\"440\" align=\"center\">\n",
    "    <em>Simplified RNN </em>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <em>Unrolled RNN</em>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15d0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572cd6f",
   "metadata": {},
   "source": [
    "## RNN Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19919ee4",
   "metadata": {},
   "source": [
    "- Input vector:&emsp;&emsp;&emsp;&emsp;&emsp;$\\large {X_t} $\n",
    "- Update hidden state: &ensp;&nbsp;$\\large H_t = tanh(W_{hh} H_{t-1} + W_{xh} X_t) $\n",
    "- Output vector:&emsp;&emsp;&emsp;&emsp;$\\large \\hat y = W_{hy} H_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4bafb",
   "metadata": {},
   "source": [
    "<img src = \"https://cs231n.github.io/assets/rnn/vanilla_rnn_mformula_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635bec2",
   "metadata": {},
   "source": [
    "<img src= \"https://cs231n.github.io/assets/rnn/vanilla_rnn_mformula_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddb651",
   "metadata": {},
   "source": [
    "### Individual multiplication Vs Multiplication of ( Concatenation of wieghts,  Concatenation of (input,hidden) )\n",
    "\n",
    "The calculation of $ {W_{hh} H_{t-1} + W_{xh} X_t} $ for the hidden state is equivalent to:<br>\n",
    "Matrix Multiplication of concatenation: of $ {X_t}  and  {H_{t-1}} $ and concatenation of ${W_{xh}} and {W_{hh}} $.<br>\n",
    "* Though this can be proven in mathematics, in the following we just use a simple code snippet to show this.\n",
    "* To begin with, we define matrices X, W_xh, H, and W_hh, whose shapes are (3, 1), (1, 4), (3, 4), and (4, 4), respectively.\n",
    "* Multiplying X by W_xh, and H by W_hh, respectively, and then adding these two multiplications, we obtain a matrix of shape (3, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03d1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, W_xh = torch.randn(3, 1), torch.randn(1, 4)\n",
    "H, W_hh = torch.randn(3, 4), torch.randn(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0fb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1852,  3.4312,  1.3261, -1.7277],\n",
       "        [ 0.0846,  2.3784, -3.5482, -4.2472],\n",
       "        [-0.9283,  0.8541, -1.3491,  1.1663]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(X, W_xh) + torch.matmul(H, W_hh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9385e7",
   "metadata": {},
   "source": [
    "* Now we concatenate the matrices $X and H$ along columns (axis 1), and the matrices $W_{xh} and W_{hh}$ along rows (axis 0).\n",
    "* These two concatenations result in matrices of shape (3, 5) and of shape (5, 4), respectively.\n",
    "* Multiplying these two concatenated matrices, we obtain the same output matrix of shape (3, 4) as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50754cd8",
   "metadata": {},
   "source": [
    "The weight matrices $ {W_x and W_h}$ are often concatenated vertically into a single weight matrix $W$ of shape (input_size + hidden_size) Ã— hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c13307",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_combined = torch.cat((X, H), 1)\n",
    "W = torch.cat((W_xh, W_hh), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8aca121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([5, 4]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_combined.shape, W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e2a7fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1852,  3.4312,  1.3261, -1.7277],\n",
       "        [ 0.0846,  2.3784, -3.5482, -4.2472],\n",
       "        [-0.9283,  0.8541, -1.3491,  1.1663]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(input_combined, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f3cb8",
   "metadata": {},
   "source": [
    "#### Therefore, by both the ways we get the same result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f630226",
   "metadata": {},
   "source": [
    "Reference:https://www.youtube.com/watch?v=qjrad0V0uJE&ab_channel=AlexanderAmini<br> [Dive into Deep Learning](https://d2l.djl.ai/chapter_recurrent-neural-networks/rnn.html#recurrent-neural-networks-with-hidden-states)<br>\n",
    "[image reference](https://cs231n.github.io/rnn/)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0127c9a",
   "metadata": {},
   "source": [
    "## Concatenated multiplication Vs Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68e2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a4823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(input_size+hidden_size, hidden_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcab459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b92e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using same weights to verify if they calculate the same result\n",
    "linear.weight.data = nn.Parameter(W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb84a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1852,  3.4312,  1.3261, -1.7277],\n",
       "        [ 0.0846,  2.3784, -3.5482, -4.2472],\n",
       "        [-0.9283,  0.8541, -1.3491,  1.1663]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.cat((X,H), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cac5de",
   "metadata": {},
   "source": [
    "#### Thus both of them gave the same results when using same weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea92fa",
   "metadata": {},
   "source": [
    "## Model without concatenation of weights and [input, hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.w_xh = nn.Parameter(torch.empty(input_size, hidden_size))\n",
    "        self.w_hh = nn.Parameter(torch.empty(hidden_size, hidden_size))\n",
    "        \n",
    "        self.w_hy = nn.Parameter(torch.empty(hidden_size, output_size))\n",
    "        \n",
    "        #using xavier initialization for input, hidden and output weight\n",
    "        nn.init.xavier_normal_(self.w_xh, gain=1.0)\n",
    "        nn.init.xavier_normal_(self.w_hh, gain=1.0)\n",
    "        nn.init.xavier_normal_(self.w_hy, gain=1.0)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        #initializing hidden state as a tensor of zeros\n",
    "        hidden = torch.zeros((1,hidden_size), dtype=torch.float32)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, x, hidden):        \n",
    "        linear_comb = torch.matmul(x, self.w_xh) + torch.matmul(hidden, self.w_hh)\n",
    "        \n",
    "        hidden = torch.tanh(linear_comb) #updating hidden state\n",
    "        \n",
    "        out = torch.matmul(hidden, self.w_hy) #calculationg output\n",
    "        return out, hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de4691",
   "metadata": {},
   "source": [
    "## Model with concatenation of weights and [input,hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa62edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.w_xh = torch.empty(input_size, hidden_size)\n",
    "        self.w_hh = torch.empty(hidden_size, hidden_size)\n",
    "        #concatenating the wieghts\n",
    "        self.W = nn.Parameter(torch.cat((self.w_xh, self.w_hh), 0))\n",
    "        \n",
    "        self.w_hy = nn.Parameter(torch.empty(hidden_size, output_size))\n",
    "        \n",
    "        #using xavier initialization for [input,hidden] weight and output weight\n",
    "        nn.init.xavier_normal_(self.W, gain=1.0)\n",
    "        nn.init.xavier_normal_(self.w_hy, gain=1.0)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        #initializing hidden state as a tensor of zeros\n",
    "        hidden = torch.zeros((1,hidden_size), dtype=torch.float32)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, x, hidden): \n",
    "        X = torch.cat((x, hidden), 1) #concatenating inputs\n",
    "        \n",
    "        linear_comb = torch.matmul(X, self.W)\n",
    "        \n",
    "        hidden = torch.tanh(linear_comb)  #updating hidden state\n",
    "        \n",
    "        out = torch.matmul(hidden, self.w_hy) #calculationg output\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385426eb",
   "metadata": {},
   "source": [
    "## Model with linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76957e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        #initializing hidden state as a tensor of zeros\n",
    "        hidden = torch.zeros((1,hidden_size), dtype=torch.float32)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, x, hidden):   \n",
    "        combined_input = torch.cat((x, hidden), 1) #concatenating inputs\n",
    "        \n",
    "        linear_comb = self.i2h(combined_input)\n",
    "        \n",
    "        hidden = torch.tanh(linear_comb) #updating hidden state\n",
    "        \n",
    "        out = self.h2o(hidden) #calculationg output\n",
    "        return out, hidden"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
